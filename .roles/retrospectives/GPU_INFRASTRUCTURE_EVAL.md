# GPU Infrastructure Evaluation for 500 Agents

**Date**: 2026-02-02
**Requested by**: User via @team_review
**Reviewers**: @mlops_engineer, @rl_engineer

---

## Executive Summary

Entrenar 500 agentes RL requiere GPU remota. El entrenamiento local es viable solo para desarrollo/testing.

**Recomendación**: RunPod A100 80GB con entrenamiento en batches.

---

## Current Training Benchmarks

| Metric | Local (RTX 3070) | Estimated |
|--------|------------------|-----------|
| Steps/second | ~2,000 | Conservative |
| 1M steps | ~8 min | Per agent |
| 5M steps | ~42 min | Per agent |
| GPU Memory | 8GB | Used ~4GB |

## 500 Agents Training Estimates

### Option A: Local Training (RTX 3070/4090)
```
500 agents × 5M steps × 42 min = 21,000 min = 350 hours = ~14.5 days
```
**Pros**: No cost, full control
**Cons**: 2 weeks downtime, wear on hardware, no parallelization

### Option B: RunPod A100 80GB (Recommended)
```
Cost: $1.99/hour
Parallel agents: 8 (memory allows)
Time per batch: ~42 min
Batches needed: 500/8 = 63 batches
Total time: 63 × 42 min = 44 hours
Total cost: 44 × $1.99 = ~$88
```
**Pros**: Fast, scalable, enterprise GPU
**Cons**: Requires data upload, network dependency

### Option C: RunPod A40 48GB (Budget)
```
Cost: $0.79/hour
Parallel agents: 4
Batches needed: 125
Total time: 88 hours
Total cost: ~$70
```
**Pros**: Cheaper per hour
**Cons**: Slower total, may not save much

### Option D: Multi-GPU Pod (Fastest)
```
4x A100 80GB: $7.96/hour
Parallel agents: 32
Total time: ~11 hours
Total cost: ~$88
```
**Pros**: Fastest completion
**Cons**: Higher complexity

---

## Recommended Strategy

### Phase 1: Development (Local)
- Train 5-10 test agents locally
- Validate environment and reward functions
- Debug any issues before scaling

### Phase 2: Initial Batch (RunPod Small)
- Train 50 agents on A100
- Run through validation pipeline
- Estimate final pass rate

### Phase 3: Full Scale (RunPod Batch)
- Train remaining 450 agents
- Use checkpoint recovery
- MLflow tracking for all runs

---

## Implementation Plan (@mlops_engineer)

### 1. RunPod Setup Script
```python
# training/runpod_launcher.py
- Create pod with Docker image
- Mount data volume
- Start training batch
- Auto-shutdown on completion
```

### 2. Data Sync Strategy
```
Option A: Upload parquet to RunPod volume (1-time, ~5GB)
Option B: Sync from S3/GCS (requires bucket)
Option C: Generate synthetic for initial tests
```
**Recommendation**: Option A (simplest)

### 3. Model Download Pipeline
```python
# training/download_models.py
- Download trained .zip files
- Verify checksums
- Register in MLflow
- Move to models/ directory
```

### 4. Fault Tolerance
- Checkpoint every 100K steps
- Auto-resume on pod restart
- Batch tracking in JSON/SQLite

---

## Training Configuration (@rl_engineer)

### Optimized Hyperparameters for Speed
```yaml
# For 500 agents, prioritize speed over perfection
ppo:
  n_steps: 2048        # Larger batches, fewer updates
  batch_size: 512      # Efficient GPU utilization
  n_epochs: 4          # Reduced from 10
  learning_rate: 3e-4  # Standard
  ent_coef: 0.01       # Encourage exploration
  vf_coef: 0.5         # Standard
  max_grad_norm: 0.5   # Gradient clipping
```

### Environment Optimization
```python
# Vectorized envs for parallelism
n_envs = 4  # Per agent, 4 parallel environments
# Total: 8 agents × 4 envs = 32 parallel simulations
```

### Timesteps Strategy
```yaml
# Tiered training
tier_1_quick:    500_000   # Initial screening
tier_2_standard: 2_000_000 # Validation candidates
tier_3_full:     5_000_000 # Top performers only
```

---

## Cost Comparison Summary

| Option | Time | Cost | Risk |
|--------|------|------|------|
| Local | 14 days | $0 | High (hardware) |
| RunPod A100 | 44 hrs | $88 | Low |
| RunPod A40 | 88 hrs | $70 | Low |
| RunPod 4xA100 | 11 hrs | $88 | Medium (complexity) |

---

## Decision

**Selected**: RunPod A100 80GB single GPU

**Rationale**:
1. Best balance of speed and cost
2. Simpler than multi-GPU setup
3. 44 hours is acceptable (~2 days)
4. $88 fits within budget constraints

**Next Actions**:
1. [ ] Create `training/runpod_launcher.py`
2. [ ] Create Docker image for RunPod
3. [ ] Test with 10 agents first
4. [ ] Upload data catalog to RunPod volume
5. [ ] Run full 500-agent batch

---

## Approval

- [x] @mlops_engineer: Approved - infrastructure is feasible
- [x] @rl_engineer: Approved - training config optimized
- [ ] User: Pending budget approval ($88 for 500 agents)

---

*Document auto-generated by governance system*
