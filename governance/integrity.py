#!/usr/bin/env python3
"""
Integrity Verification System

Protects critical files from unauthorized modification.
Verifies checksums and alerts on discrepancies.
"""

import hashlib
import json
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import structlog

logger = structlog.get_logger()

# Project root
PROJECT_ROOT = Path(__file__).parent.parent

# Protected files that require formal change process
# Note: CHECKSUMS.md is excluded from checksumming itself to avoid circular dependency
PROTECTED_FILES = [
    "CLAUDE.md",
    ".rules/IMMUTABLE_RULES.md",
    "config/autonomous_config.yaml",
    "governance/governance_engine.py",
]

# Files that can NEVER be modified by automated processes
IMMUTABLE_FILES = [
    ".rules/IMMUTABLE_RULES.md",
]

# Checksum storage
CHECKSUMS_FILE = PROJECT_ROOT / ".rules" / "CHECKSUMS.md"
CHECKSUMS_JSON = PROJECT_ROOT / ".rules" / ".checksums.json"
WARNINGS_FILE = PROJECT_ROOT / ".rules" / "WARNINGS.md"


def compute_sha256(file_path: Path) -> str:
    """Compute SHA256 hash of a file."""
    if not file_path.exists():
        return "FILE_NOT_FOUND"

    sha256_hash = hashlib.sha256()
    with open(file_path, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()


def load_checksums() -> Dict[str, str]:
    """Load stored checksums from JSON file."""
    if CHECKSUMS_JSON.exists():
        try:
            with open(CHECKSUMS_JSON, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            pass
    return {}


def save_checksums(checksums: Dict[str, str]) -> None:
    """Save checksums to both JSON and MD files."""
    # Save JSON (machine-readable)
    with open(CHECKSUMS_JSON, "w", encoding="utf-8") as f:
        json.dump(checksums, f, indent=2)

    # Update MD file (human-readable)
    timestamp = datetime.now().isoformat()
    lines = [
        "# Protected Files Checksums",
        "",
        "> **WARNING**: This file is automatically generated.",
        "> DO NOT MODIFY MANUALLY.",
        "> Any discrepancy will trigger security alerts.",
        "",
        f"**Last Updated**: {timestamp}",
        "",
        "## Protected Files",
        "",
        "| File | SHA256 Hash | Status |",
        "|------|-------------|--------|",
    ]

    for file_path, hash_value in checksums.items():
        status = "OK" if hash_value != "FILE_NOT_FOUND" else "MISSING"
        short_hash = hash_value[:16] + "..." if len(hash_value) > 16 else hash_value
        lines.append(f"| {file_path} | `{short_hash}` | {status} |")

    lines.extend([
        "",
        "## Verification Log",
        "",
        "Checksums are verified at:",
        "- Session start (mandatory)",
        "- Pre-commit hook",
        "- Post-merge hook",
        "",
        "## Hash Algorithm",
        "",
        "SHA256 is used for all checksums.",
    ])

    with open(CHECKSUMS_FILE, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))


def initialize_checksums() -> Dict[str, str]:
    """Initialize checksums for all protected files."""
    checksums = {}
    for rel_path in PROTECTED_FILES:
        file_path = PROJECT_ROOT / rel_path
        checksums[rel_path] = compute_sha256(file_path)

    save_checksums(checksums)
    logger.info("Checksums initialized", files=len(checksums))
    return checksums


def verify_integrity() -> Tuple[bool, List[str]]:
    """
    Verify integrity of all protected files.

    Returns:
        Tuple of (all_ok, list_of_violations)
    """
    stored = load_checksums()

    if not stored:
        # First run - initialize
        stored = initialize_checksums()
        return True, []

    violations = []

    for rel_path in PROTECTED_FILES:
        file_path = PROJECT_ROOT / rel_path
        current_hash = compute_sha256(file_path)
        stored_hash = stored.get(rel_path, "NOT_TRACKED")

        if current_hash != stored_hash:
            violations.append(
                f"{rel_path}: expected {stored_hash[:16]}..., got {current_hash[:16]}..."
            )
            logger.warning(
                "Integrity violation detected",
                file=rel_path,
                expected=stored_hash[:16],
                actual=current_hash[:16],
            )

    return len(violations) == 0, violations


def check_immutable_files(changed_files: List[str]) -> Tuple[bool, List[str]]:
    """
    Check if any immutable files are being modified.

    Returns:
        Tuple of (allowed, list_of_blocked_files)
    """
    blocked = []

    for file_path in changed_files:
        # Normalize path
        normalized = file_path.replace("\\", "/")

        for immutable in IMMUTABLE_FILES:
            if normalized.endswith(immutable) or normalized == immutable:
                blocked.append(file_path)
                logger.error(
                    "Attempt to modify immutable file BLOCKED",
                    file=file_path,
                )

    return len(blocked) == 0, blocked


def check_protected_files(changed_files: List[str]) -> Tuple[bool, List[str]]:
    """
    Check if protected files are being modified without formal process.

    Returns:
        Tuple of (allowed, list_of_warnings)
    """
    warnings = []

    for file_path in changed_files:
        normalized = file_path.replace("\\", "/")

        for protected in PROTECTED_FILES:
            if normalized.endswith(protected) or normalized == protected:
                # Protected file modification - log warning
                warnings.append(f"Protected file modified: {file_path}")
                logger.warning(
                    "Protected file modification detected",
                    file=file_path,
                )

    return True, warnings  # Allow but warn


def update_checksums_for_files(files: List[str]) -> None:
    """Update checksums for specific files after approved changes."""
    stored = load_checksums()

    for file_path in files:
        normalized = file_path.replace("\\", "/")

        for protected in PROTECTED_FILES:
            if normalized.endswith(protected) or normalized == protected:
                full_path = PROJECT_ROOT / protected
                stored[protected] = compute_sha256(full_path)
                logger.info("Checksum updated", file=protected)

    save_checksums(stored)


def log_warning(message: str, severity: str = "WARNING") -> None:
    """Log a warning to WARNINGS.md."""
    timestamp = datetime.now().isoformat()

    entry = f"\n## [{timestamp}] {severity}\n{message}\n"

    if WARNINGS_FILE.exists():
        content = WARNINGS_FILE.read_text(encoding="utf-8")
    else:
        content = "# Warnings Log\n\nSecurity and integrity warnings.\n"

    # Keep last 100 entries
    lines = content.split("\n## ")
    if len(lines) > 100:
        lines = lines[:1] + lines[-99:]
        content = "\n## ".join(lines)

    WARNINGS_FILE.write_text(content + entry, encoding="utf-8")


def verify_session_protocol() -> bool:
    """
    Check if session was started with proper protocol.
    Called by other tools to verify compliance.
    """
    session_marker = PROJECT_ROOT / ".rules" / ".session_active"

    if not session_marker.exists():
        log_warning(
            "Session without protocol detected. "
            "Run scripts/session_start.py at the beginning of each session.",
            severity="PROTOCOL_VIOLATION"
        )
        return False

    # Check if marker is recent (within last 24 hours)
    try:
        marker_time = datetime.fromisoformat(
            session_marker.read_text(encoding="utf-8").strip()
        )
        age = datetime.now() - marker_time
        if age.total_seconds() > 86400:  # 24 hours
            log_warning(
                f"Session marker expired ({age.total_seconds() / 3600:.1f} hours old). "
                "Run scripts/session_start.py to refresh.",
                severity="SESSION_EXPIRED"
            )
            return False
    except Exception:
        pass

    return True


def mark_session_active() -> None:
    """Mark that a proper session has started."""
    session_marker = PROJECT_ROOT / ".rules" / ".session_active"
    session_marker.write_text(
        datetime.now().isoformat(),
        encoding="utf-8"
    )


# CLI interface
def main():
    """CLI for integrity verification."""
    import argparse

    parser = argparse.ArgumentParser(description="Integrity Verification System")
    parser.add_argument("--verify", action="store_true", help="Verify all checksums")
    parser.add_argument("--init", action="store_true", help="Initialize checksums")
    parser.add_argument("--update", nargs="+", help="Update checksums for files")
    parser.add_argument("--check-files", nargs="+", help="Check if files can be modified")

    args = parser.parse_args()

    if args.init:
        initialize_checksums()
        print("[OK] Checksums initialized")

    elif args.verify:
        ok, violations = verify_integrity()
        if ok:
            print("[OK] All checksums verified")
        else:
            print("[FAIL] Integrity violations detected:")
            for v in violations:
                print(f"  - {v}")
            sys.exit(1)

    elif args.update:
        update_checksums_for_files(args.update)
        print(f"[OK] Updated checksums for {len(args.update)} files")

    elif args.check_files:
        # Check immutable
        ok, blocked = check_immutable_files(args.check_files)
        if not ok:
            print("[BLOCKED] Cannot modify immutable files:")
            for b in blocked:
                print(f"  - {b}")
            sys.exit(1)

        # Check protected
        ok, warnings = check_protected_files(args.check_files)
        if warnings:
            print("[WARNING] Protected files being modified:")
            for w in warnings:
                print(f"  - {w}")

        print("[OK] File modifications allowed")

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
